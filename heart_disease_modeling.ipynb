{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = pd.read_csv('heart_data_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the outcome variable (target) is binary, I'm going to use a logistic regression.\n",
    "\n",
    "First, I will split the data into two sets: the target variable and the predictors/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age', 'sex', 'cp', 'fbs', 'trestbps', 'chol', \n",
    "           'restecg', 'thalach', 'exang', 'oldpeak', \n",
    "           'slope', 'ca', 'thal']\n",
    "\n",
    "X = heart_data[features]\n",
    "y = heart_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to split the data into training and testing datasets\n",
    "\n",
    "Logistic regression will use scikit learn:\n",
    "\n",
    "> train_test_split\n",
    "\n",
    "> LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using train test split to train; \n",
    "#test size = 1/4 of the data will be used to test (3/4 for training)\n",
    "#random_state = select test data randomly\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression()\n",
    "\n",
    "#fit the model with training data\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict y (target) using test data\n",
    "y_predict = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to evaluate the model.\n",
    "\n",
    "To do this, I'll use a confusion matrix to compare the predictions (y_predict) to the test data (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34,  1],\n",
       "       [ 3, 33]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = metrics.confusion_matrix(y_test, y_predict)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34 and 33 are accurate predictions (0, 1)\n",
    "1 and 3 are inaccurate predictions (0, 1)\n",
    "\n",
    "Seems pretty accurate, but let's visualize this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 257.44, 'Predicted')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEvCAYAAACTw2ybAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAYb0lEQVR4nO3deZhldX3n8fenu9lXFVQGUQjgVccEGH2ISySKgpAYt5gILgFk7InBfSFEGbcxo0TjNnEcW0EREdeQwRV5fFAUAdkNCAUMKrIkCIrs0Mt3/rinsah0V9Ut6tQ9dfr9ep7zPHXPPfd3vl3dXZ/6/s65v5uqQpKkNi0ZdwGSpP4zbCRJrTNsJEmtM2wkSa0zbCRJrTNsJEmtM2zUeUk2S/K1JL9N8uUHMM5Lk3xnPmsbhyTfSnLIuOuQRmHYaN4keUmS85LcnuSG5ofiH83D0C8CHgY8pKr+Yq6DVNWJVbX/PNRzP0menqSSnDxl/x7N/u/Ncpx3JvncTMdV1YFVdfwcy5XGwrDRvEjyRuDDwP9kGAyPBP438Lx5GP5RwBVVtWoexmrLr4AnJ3nIpH2HAFfM1wky5P9ZLUr+w9UDlmQb4N3AEVX1z1V1R1WtrKqvVdVbmmM2SfLhJNc324eTbNI89/Qk1yZ5U5Ibm67osOa5dwFvB17cdEyHT+0AkuzcdBDLmseHJrk6yW1JfpbkpZP2/3DS656S5Nxmeu7cJE+Z9Nz3kvyPJGc243wnyXbTfBvuBf4FOKh5/VLgxcCJU75XH0nyyyS3Jjk/ydOa/QcAb53057x4Uh1/n+RM4E7g95p9/7V5/uNJvjpp/GOSfDdJZv0XKC0Aw0bz4cnApsDJ0xzzNuBJwJ7AHsDewNGTnn84sA2wI3A48LEkD6qqdzDslr5YVVtW1bHTFZJkC+CjwIFVtRXwFOCidRz3YOAbzbEPAT4IfGNKZ/IS4DDgocDGwJunOzfwWeCvmq+fDVwCXD/lmHMZfg8eDHwe+HKSTavq21P+nHtMes3LgeXAVsAvpoz3JuD3myB9GsPv3SHlOlTqGMNG8+EhwE0zTHO9FHh3Vd1YVb8C3sXwh+haK5vnV1bVN4HbgcEc61kDPD7JZlV1Q1Vduo5j/hS4sqpOqKpVVXUScDnwZ5OO+XRVXVFVdwFfYhgS61VVPwIenGTAMHQ+u45jPldVNzfn/EdgE2b+c36mqi5tXrNyynh3Mvw+fhD4HPCaqrp2hvGkBWfYaD7cDGy3dhprPf4T9/+t/BfNvvvGmBJWdwJbjlpIVd3BcPrqr4EbknwjyWNmUc/amnac9Pjf5lDPCcCrgWewjk4vyZuTXNZM3d3CsJubbnoO4JfTPVlV5wBXA2EYilLnGDaaD2cB9wDPn+aY6xle6F/rkfzHKabZugPYfNLjh09+sqpOrar9gB0YdiufnEU9a2u6bo41rXUC8DfAN5uu4z7NNNeRwF8CD6qqbYHfMgwJgPVNfU07JZbkCIYd0vXN+FLnGDZ6wKrqtwwv4n8syfOTbJ5koyQHJvmH5rCTgKOTbN9caH87w2mfubgI2CfJI5ubE/5u7RNJHpbkec21m3sYTsetWccY3wQe3dyuvSzJi4HHAV+fY00AVNXPgD9meI1qqq2AVQzvXFuW5O3A1pOe/3dg51HuOEvyaOA9wMsYTqcdmWTa6T5pHAwbzYvm+sMbGV70/xXDqZ9XM7xDC4Y/EM8DfgL8K3BBs28u5zoN+GIz1vncPyCWNHVcD/ya4Q/+V61jjJuB5zC8wH4zw47gOVV101xqmjL2D6tqXV3bqcC3Gd4O/Qvgbu4/Rbb2Das3J7lgpvM005afA46pqour6kqGd7SdsPZOP6kr4k0rkqS22dlIklpn2EiSWmfYSJJaZ9hIklpn2EiSWmfYaNFJsjrJRUkuSfLlJJvP/Kr1jvX0JF9vvn5ukqOmOXbbJH8zh3O8M8lM66pJvWbYaDG6q6r2rKrHM1xt+a8nPznXpfir6pSqet80h2zLcHUASSMybLTY/QDYrfmYgYkkn2W42vJOSfZPclaSC5oOaEsYLuef5PLmjZMvXDtQs3LyPzVfPyzJyUkubranAO8Ddm26qvc3x72l+XiCnzQfh7B2rLcluaL5SIO5Ligq9cZ0CydKnda8g/5Ahu/KB9id4fL6ZzdL4hwNPKuq7kjyt8Abm+VzPgnsC1zFcCWCdfko8P2qekHz2TRbAkcBj6+qPZvz79+cc2+G65udkmQfhmu3HcRwlehlDFdLOH9+//TS4mLYaDHaLMnaz6j5AXAszSrOVXV2s/9JDNc6O7P5HLGNGS4Y+hjgZ83SLmT4IWzL13GOfWk+m6aqVgO/TfKgKcfs32wXNo+3ZBg+WwEnr12IM8kpD+hPK/WAYaPF6K613cVaTaDcMXkXcFpVHTzluPlcpDLAe6vqE1PO8fp5PIfUC16zUV+dDTw1yW4w/ATPZoXkyxmurLxrc9zB63n9d2kW8EyytFld+jaGXctapwKvmHQtaMckDwXOAJ6fZLMkW3H/D2STNkh2NovYYDDYlOEPtk0Y/l1+ZWJi4h2Tnv8o8IqJiYmRP4RssauqXyU5FDhp0grIR1fVFUmWM/wI6DsZTsNttY4hXgesSHI4sBp4VVWdleTMJJcA36qqtyR5LHBW01ndDrysqi5I8kXgYuBGhh8F3VfHMVw9+0bg8WOuRR3mqs+L2GAwCLDFxMTE7YPBYCPgh8DrJiYmzh4MBk9k+APzBRti2GjB7MMwZD+LYaNptNbZNB/F+zx+9zG71wGnVNVlbZ1zQzMxMVEM/6MDbNRsNRgMlgLvB14CvGBM5WnDcAaw87iLUPe1cs2muc30CwwvoP642cJwSmO979DW6AaDwdLBYHARw2mM0yYmJs5h+KFlp0xMTNww3uokaaiVabQkVwD/uapWTtm/MXBpVe2+ntctp7kN9ROfeNoTli9/7LzX1le33rqSI464lNe+dmc++MGrOeGEPVm2bAl77XUGF164z7jLWxR+95ZMjeJR2zyEr7/kCH7/4+8edymLUr3jE5nfEf/biD/U5/v869bWNNoamvc9TNm/A+v+PHgAqmoFsGL4aNRv2IZt66034g//cFvOOecWrrnmLvbf/xwA7rprDfvtdzannfakMVcoaUPWVti8Hvhukiv53WesPxLYjeEUj+bBr399L8uWha233oi7717Nj370G175yp0488yn3nfMXnudYdBIG5BRf0tfkLaGlsKmqr7dvKdhb+5/g8C5zbuxNQ9uvPFejjrqclavLqqKAw54KM94xnbjLksbkM+/8HCevvOA7Tbfkl++4X2843tf47gLzxx3WRu0Ua+MZIHSpsO3PjuNpoXlNRuNw3xfs1ldo/3sXJrFfc1GkjQGI/cPC9TZGDaS1CNdnRIybCSpR7p6ZcSwkaQe6WjWGDaS1CdrOpo2ho0k9YjTaJKk1nU0awwbSeoTOxtJUus6mjWGjST1iZ2NJKl1Hc0aw0aS+sTORpLUuo5mjWEjSX1iZyNJal1Hs8awkaQ+sbORJLXOsJEkta6jWWPYSFKf2NlIklrX0awxbCSpTwwbSVLrujqNtmTcBUiS5k+NuM0kyaZJfpzk4iSXJnlXs3+XJOckuSrJF5NsPN04ho0k9UjVaNss3APsW1V7AHsCByR5EnAM8KGq2g34DXD4dIMYNpLUI/Pd2dTQ7c3DjZqtgH2BrzT7jweeP904ho0k9ciaGm1LsjzJeZO25VPHTLI0yUXAjcBpwP8DbqmqVc0h1wI7TleXNwhIUo+MeoNAVa0AVsxwzGpgzyTbAicDjxm1LsNGknqkzZvRquqWJKcDTwa2TbKs6W4eAVw33WudRpOkHpnvGwSSbN90NCTZDNgPuAw4HXhRc9ghwP+dbhw7G0nqkRY6mx2A45MsZdigfKmqvp7kp8AXkrwHuBA4drpBDBtJ6pH5flNnVf0E2Gsd+68G9p7tOIaNJPVIRxcQMGwkqU+6ulyNYSNJPdLRrDFsJKlP7GwkSa3raNYYNpLUJ3Y2kqTWdTRrDBtJ6hM7G0lS6zqaNYaNJPWJnY0kqXUdzRrDRpL6xM5GktS6jmaNYSNJfWJnI0lqXUezxrCRpD5Zs2bcFaybYSNJPWJnI0lqnddsJEmt62jWGDaS1CeGjSSpdU6jSZJa19GsMWwkqU/sbCRJreto1hg2ktQndjaSpNZ1NGsMG0nqEzsbSVLrOpo1ho0k9YmdjSSpdR3NGsNGkvrEzkaS1LqOZo1hI0l9YmcjSWpdR7PGsJGkPulqZ7Nk3AVIkuZPjbjNJMlOSU5P8tMklyZ53ZTn35Skkmw33Th2NpLUI2vmv7NZBbypqi5IshVwfpLTquqnSXYC9geumWkQOxtJ6pGq0baZx6sbquqC5uvbgMuAHZunPwQcySyaJMNGknpk1Gm0JMuTnDdpW76+sZPsDOwFnJPkecB1VXXxbOpyGk2SemTUGwSqagWwYqbjkmwJfBV4PcOptbcynEKbFTsbSeqR+b5BACDJRgyD5sSq+mdgV2AX4OIkPwceAVyQ5OHrG8PORpJ6ZL5vfU4S4Fjgsqr64PAc9a/AQycd83PgiVV10/rGsbORpB5pobN5KvByYN8kFzXbn4xal52NJPXIfHc2VfVDIDMcs/NM4xg2ktQjHV1AwLCRpD7p6nI1ho0k9YhhI0lqXUezxrCRpD6xs5Ekta6jWWPYSFKfGDaSpNY5jSZJal1Hs8awkaQ+sbORJLWuo1lj2EhSn9jZSJJa19GsMWwkqU/sbCRJrVtj2EiS2tbRrDFsJKlPnEaTJLWuo1lj2EhSn9jZSJJa19GsMWwkqU/sbCRJreto1hg2ktQndjaSpNZ1NGsMG0nqEzsbSVLrOpo1ho0k9YmdjSSpdR3NGsNGkvrEzkaS1LqOZs36wybJ15im7qp6bisVSZLmbDF2Nh9YsCokSfOio1mz/rCpqu8vZCGSpAduMXY2ACTZHXgv8Dhg07X7q+r3WqxLkjQHXQ2bJbM45tPAx4FVwDOAzwKfa7MoSdLc1IjbQplN2GxWVd8FUlW/qKp3An/ablmSpLlYU6NtC2U2YXNPkiXAlUleneQFwJYt1yVJmoP57mySHJfkxiSXTNq3Z5Kzk1yU5Lwke880zmzC5nXA5sBrgScALwcOmcXrJEkLrGq0bRY+AxwwZd8/AO+qqj2BtzePpzXjDQJVdW7z5e3AYbMqTZI0FvM9M1ZVZyTZeR2n2br5ehvg+pnGmc3daKezjvqrat8Zq5QkLahR70ZLshxYPmnXiqpaMcPLXg+cmuQDDGfInjLTeWazXM2bJ329KfDnDO9MkyR1zKidTRMsM4XLVK8C3lBVX03yl8CxwLOme8FsptHOn7LrzCQ/HrEwSdICWKD32RzC8Ho+wJeBT830gtlMoz140sMlDG8S2GYu1Y1i2/e1fQbp/u4+etwVSA/cAt3NfD3wx8D3gH2BK2d6wWym0c5nWH8YTp/9DDh8ziVKkloz351NkpOApwPbJbkWeAfwSuAjSZYBd3P/az7rNJuweWxV3T3l5JuMXLEkqXUt3I128HqeesIo48zmfTY/Wse+s0Y5iSRpYbTwPpt5Md3n2Twc2BHYLMleDKfRYHhv9eYLUJskaUQdXYdz2mm0ZwOHAo8A/pHfhc2twFvbLUuSNBddXfV5us+zOR44PsmfV9VXF7AmSdIcdTRrZnXN5glJtl37IMmDkrynxZokSXPU1Ws2swmbA6vqlrUPquo3wJ+0V5Ikaa66+nk2s7n1eWmSTarqHoAkmwHe+ixJHbTortlMciLw3SSfZniTwKHA8W0WJUmam45mzazWRjsmycUMF1kr4FTgUW0XJkka3WLubAD+nWHQ/AXD5Wq8O02SOqijWTPtmzofDRzcbDcBXwRSVc9YoNokSSNajJ3N5cAPgOdU1VUASd6wIFVJkuZkTUfDZrpbn18I3ACcnuSTSZ7J71YRkCR1UFdvfV5v2FTVv1TVQcBjgNMZfgzoQ5N8PMn+C1WgJGn2Fu2bOqvqjqr6fFX9GcN10i4E/rb1yiRJI1t0nc26VNVvqmpFVT2zrYIkSXPX1c5mtrc+S5IWgY7eH2DYSFKfLMZbnyVJi4xhI0lqXUezxrCRpD6xs5Ekta6jWWPYSFKfGDaSpNY5jSZJal1Hs8awkaQ+sbORJLWuo1lj2EhSn9jZSJJa19GsMWwkqU/sbCRJreto1hg2ktQndjaSpNatMWwkSW3raNYYNpLUJ12dRlsy7gIkSfOnRtxmkuS4JDcmuWTSvvcnuTzJT5KcnGTbmcYxbCSpR6pG22bhM8ABU/adBjy+qv4AuAL4u5kGMWwkqUfmu7OpqjOAX0/Z952qWtU8PBt4xEzjGDaS1COjdjZJlic5b9K2fMRTvgL41kwHeYOAJPXIqPcHVNUKYMVczpXkbcAq4MSZjjVsJKlHFuputCSHAs8Bnlk181kNG0nqkYXImiQHAEcCf1xVd87mNV6zkaQeme+70ZKcBJwFDJJcm+Rw4J+ArYDTklyU5P/MNI6djST1yHx3NlV18Dp2HzvqOIaNJPVIV1cQMGwkqUc6mjWGjST1iZ2NJKl1Hc0aw0aS+sTORpLUOsNGktS6jmaNYSNJfWJnI0lqXUezxrCRpD5Z09G0MWwkqUc6mjWGjST1iddsJEmt62jWGDaS1Cd2NpKk1nU0awwbSeoTOxtJUus6mjWGjST1iZ2NJKl1Hc0aw0aS+sTORpLUuo5mjWEjSX1iZyNJal1Hs8awkaQ+sbORJLWuo1lj2EhSn9jZSJJa19GsMWwkqU/sbCRJreto1hg2ktQndjaSpNatMWwkSW3raNYYNpLUJ06jSZJa19GsMWwkqU/sbCRJreto1rBk3AVIkuZP1WjbbCTZNslXklye5LIkTx61LjsbSeqRlqbRPgJ8u6pelGRjYPNRBzBsJKlH5jtrkmwD7AMcClBV9wL3jjqO02iS1CM14pZkeZLzJm3Lpwy5C/Ar4NNJLkzyqSRbjFqXYSNJPTLqNZuqWlFVT5y0rZgy5DLgvwAfr6q9gDuAo0aty7CRpB4ZtbOZhWuBa6vqnObxVxiGz0gMG0nqkfm+G62q/g34ZZJBs+uZwE9HrcsbBCSpR1p6n81rgBObO9GuBg4bdQDDRpJ6pI1bn6vqIuCJD2QMw0aSeqSrKwgYNpLUI66NJklqXUezxrCRpD6xs5Ekta6jWWPYSFKf2NlIklq3xrCRJLWto1lj2EhSnziNJklqXUezxrCRpD6xs5Ekta6jWWPYSFKf2NlIklrX0awxbCSpT+xsJEmt62jWGDaS1Cd2NpKk1nU0awwbSeoTOxtJUus6mjWGjST1iZ2NJKl1Hc0aw0aS+sTORpLUuo5mjWEjSX1iZyNJal1Hs8awkaQ+sbNRqzZZuoxvvvTNbLJsGUuzlFMmLuC9P/zauMtSD91zz2oO+6uLuPfeNaxeVTxr/+054jW78I6jL+fSS2+jCh6182a85+8fw+Zb+CNmoa0xbNSme1av4rknfYg7Vt7DsiVL+PbLjuS0qy/hvOt/Nu7S1DMbb7yETx23B5tvsYyVK9dwyMsu5I/2eTBvOWo3ttxy+CPl/cdcxUmfv47DX/moMVe74elo1hg2fXLHynsA2GjJUjZaspTqaj+tRS3JfR3LqlXFqlVFyH1BU1XcffcakoyzzA1WV//bL3jYJDmsqj690OfdECxJ+P6hb2OXB23Ppy74Puff8PNxl6SeWr26OOhF53HNNXdx0Et25A/22BqA//7Wy/nBD25m11234M1H7jrmKjdMHc0astC//Sa5pqoeuZ7nlgPLm4crqmrFwlXWH7vvvvvrrrzyyucDrwEuGXc96q/BYLAtcPINN9zw/VtvvfWdzb6lwP8Czp2YmPAXSwEthU2Sn6zvKeDRVbXJvJ9U90lyXlWdAtwJfGDc9ajfBoPB22+++eZX3nTTTTtN2rcPcOTExMRzxliaOqStabSHAc8GfjNlf4AftXTODd32wErgli222CLAfsAx4y1JfTQYDLYHVk5MTNwyGAw2A/a799577x4MBrtNTExcNRgMAjwXuHy8lapL2gqbrwNbVtVFU59I8r2Wzrmh2wE4Hlh64YUX7g68l+HfgzTfdgCOb6bLlgBfuu222567ww47HD8YDLZm+EvlxcCrxlmkumXBr9mofUmWe71LC8l/c5qJYSNJat2ScRcgSeo/w0aS1DrDpkeSHJBkIslVSY4adz3qvyTHJbkxie/n0rQMm55IshT4GHAg8Djg4CSPG29V2gB8Bjhg3EWo+wyb/tgbuKqqrq6qe4EvAM8bc03quao6A/j1uOtQ9xk2/bEj8MtJj69t9knS2Bk2kqTWGTb9cR2w06THj2j2SdLYGTb9cS6we5JdkmwMHAScMuaaJAkwbHqjqlYBrwZOBS4DvlRVl463KvVdkpOAs4BBkmuTHD7umtRNLlcjSWqdnY0kqXWGjSSpdYaNJKl1ho0kqXWGjSSpdYaNJKl1ho0kqXX/H6lsFJ0ktawMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Using a heatmap to visualize the confusion matrix\n",
    "\n",
    "class_names = [0, 1]\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(conf_matrix),\n",
    "           annot = True, cmap = 'summer')\n",
    "\n",
    "ax.xaxis.set_label_position('top')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.title(\"Confusion Matrix\", y=1.1)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better evaluate the model, I'm going to use accuracy, precision, and recall; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9436619718309859\n",
      "precision:  0.9705882352941176\n",
      "recall:  0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \", metrics.accuracy_score(y_test, y_predict))\n",
    "print('precision: ', metrics.precision_score(y_test, y_predict))\n",
    "print('recall: ', metrics.recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 94%.\n",
    "\n",
    "A precision rate of .97 means that when the model predicts that someone has heart disease, they have it 97% of the time. That is, very few (3%) false positives.\n",
    "\n",
    "Recall .92 = Those with heart diease in the data set are identified 92% of the time. That is, 8% false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve to explore accuracy (true/false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = reg.predict_proba(X_test)[::, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot(fpr, tpr, label = \"data 1, auc\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auc is .95, so it's a good classifier (1 is perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The accuracy of this model is pretty high with all the variables as features. However, some features didn't seem like they would be very predictive based on the exploratory data analysis, so I will run a logistic regression analysis to see the p-values/coefficients associated with each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.324926\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>target</td>      <th>  No. Observations:  </th>  <td>   283</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   269</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    13</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 14 Dec 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.5266</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>17:38:31</td>     <th>  Log-Likelihood:    </th> <td> -91.954</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -194.23</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.583e-36</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -4.7992</td> <td>    3.046</td> <td>   -1.576</td> <td> 0.115</td> <td>  -10.769</td> <td>    1.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>   -0.0092</td> <td>    0.025</td> <td>   -0.365</td> <td> 0.715</td> <td>   -0.058</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fbs</th>       <td>   -0.4602</td> <td>    0.592</td> <td>   -0.777</td> <td> 0.437</td> <td>   -1.621</td> <td>    0.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex</th>       <td>    1.8029</td> <td>    0.504</td> <td>    3.579</td> <td> 0.000</td> <td>    0.816</td> <td>    2.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp</th>        <td>   -0.7902</td> <td>    0.197</td> <td>   -4.015</td> <td> 0.000</td> <td>   -1.176</td> <td>   -0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trestbps</th>  <td>    0.0247</td> <td>    0.013</td> <td>    1.921</td> <td> 0.055</td> <td>   -0.000</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chol</th>      <td>    0.0081</td> <td>    0.005</td> <td>    1.646</td> <td> 0.100</td> <td>   -0.002</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>restecg</th>   <td>   -0.5297</td> <td>    0.381</td> <td>   -1.391</td> <td> 0.164</td> <td>   -1.276</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thalach</th>   <td>   -0.0232</td> <td>    0.012</td> <td>   -2.009</td> <td> 0.045</td> <td>   -0.046</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exang</th>     <td>    0.8211</td> <td>    0.446</td> <td>    1.839</td> <td> 0.066</td> <td>   -0.054</td> <td>    1.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oldpeak</th>   <td>    0.5738</td> <td>    0.239</td> <td>    2.397</td> <td> 0.017</td> <td>    0.105</td> <td>    1.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slope</th>     <td>   -0.7546</td> <td>    0.373</td> <td>   -2.021</td> <td> 0.043</td> <td>   -1.486</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ca</th>        <td>    1.2650</td> <td>    0.279</td> <td>    4.533</td> <td> 0.000</td> <td>    0.718</td> <td>    1.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thal</th>      <td>    1.1812</td> <td>    0.327</td> <td>    3.610</td> <td> 0.000</td> <td>    0.540</td> <td>    1.822</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   No. Observations:                  283\n",
       "Model:                          Logit   Df Residuals:                      269\n",
       "Method:                           MLE   Df Model:                           13\n",
       "Date:                Sat, 14 Dec 2019   Pseudo R-squ.:                  0.5266\n",
       "Time:                        17:38:31   Log-Likelihood:                -91.954\n",
       "converged:                       True   LL-Null:                       -194.23\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.583e-36\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -4.7992      3.046     -1.576      0.115     -10.769       1.170\n",
       "age           -0.0092      0.025     -0.365      0.715      -0.058       0.040\n",
       "fbs           -0.4602      0.592     -0.777      0.437      -1.621       0.700\n",
       "sex            1.8029      0.504      3.579      0.000       0.816       2.790\n",
       "cp            -0.7902      0.197     -4.015      0.000      -1.176      -0.404\n",
       "trestbps       0.0247      0.013      1.921      0.055      -0.000       0.050\n",
       "chol           0.0081      0.005      1.646      0.100      -0.002       0.018\n",
       "restecg       -0.5297      0.381     -1.391      0.164      -1.276       0.217\n",
       "thalach       -0.0232      0.012     -2.009      0.045      -0.046      -0.001\n",
       "exang          0.8211      0.446      1.839      0.066      -0.054       1.696\n",
       "oldpeak        0.5738      0.239      2.397      0.017       0.105       1.043\n",
       "slope         -0.7546      0.373     -2.021      0.043      -1.486      -0.023\n",
       "ca             1.2650      0.279      4.533      0.000       0.718       1.812\n",
       "thal           1.1812      0.327      3.610      0.000       0.540       1.822\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.logit(\n",
    "    formula=\"target ~ age + fbs + \\\n",
    "    sex + cp + trestbps + chol+ restecg + \\\n",
    "                  thalach + exang + oldpeak + \\\n",
    "                  slope + ca + thal\", data = heart_data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all features the psuedo-R-square is ~.53\n",
    "\n",
    "I'm going to run this analysis again dropping everything with p > .05 (age, fbs, chol, trestbps, restecg, exang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.349566\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>target</td>      <th>  No. Observations:  </th>  <td>   283</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   275</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 14 Dec 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.4907</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>17:44:20</td>     <th>  Log-Likelihood:    </th> <td> -98.927</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -194.23</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.115e-37</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1331</td> <td>    1.582</td> <td>    0.084</td> <td> 0.933</td> <td>   -2.969</td> <td>    3.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex</th>       <td>    1.5630</td> <td>    0.447</td> <td>    3.497</td> <td> 0.000</td> <td>    0.687</td> <td>    2.439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp</th>        <td>   -0.8259</td> <td>    0.180</td> <td>   -4.576</td> <td> 0.000</td> <td>   -1.180</td> <td>   -0.472</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thalach</th>   <td>   -0.0246</td> <td>    0.010</td> <td>   -2.549</td> <td> 0.011</td> <td>   -0.044</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oldpeak</th>   <td>    0.6422</td> <td>    0.220</td> <td>    2.915</td> <td> 0.004</td> <td>    0.210</td> <td>    1.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slope</th>     <td>   -0.7090</td> <td>    0.348</td> <td>   -2.037</td> <td> 0.042</td> <td>   -1.391</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ca</th>        <td>    1.1911</td> <td>    0.249</td> <td>    4.782</td> <td> 0.000</td> <td>    0.703</td> <td>    1.679</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thal</th>      <td>    1.1670</td> <td>    0.301</td> <td>    3.882</td> <td> 0.000</td> <td>    0.578</td> <td>    1.756</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   No. Observations:                  283\n",
       "Model:                          Logit   Df Residuals:                      275\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Sat, 14 Dec 2019   Pseudo R-squ.:                  0.4907\n",
       "Time:                        17:44:20   Log-Likelihood:                -98.927\n",
       "converged:                       True   LL-Null:                       -194.23\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.115e-37\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1331      1.582      0.084      0.933      -2.969       3.235\n",
       "sex            1.5630      0.447      3.497      0.000       0.687       2.439\n",
       "cp            -0.8259      0.180     -4.576      0.000      -1.180      -0.472\n",
       "thalach       -0.0246      0.010     -2.549      0.011      -0.044      -0.006\n",
       "oldpeak        0.6422      0.220      2.915      0.004       0.210       1.074\n",
       "slope         -0.7090      0.348     -2.037      0.042      -1.391      -0.027\n",
       "ca             1.1911      0.249      4.782      0.000       0.703       1.679\n",
       "thal           1.1670      0.301      3.882      0.000       0.578       1.756\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.logit(\n",
    "    formula=\"target ~ \\\n",
    "    sex + cp + thalach + oldpeak + \\\n",
    "                  slope + ca + thal\", data = heart_data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared is about the same, let's test the model again to see if it's better or worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9154929577464789\n",
      "precision:  0.96875\n",
      "recall:  0.8611111111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "features = ['sex', 'cp', 'thalach', 'oldpeak', 'slope', 'ca', 'thal']\n",
    "\n",
    "X = heart_data[features]\n",
    "y = heart_data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "reg = LogisticRegression()\n",
    "\n",
    "#fit the model with training data\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_predict = reg.predict(X_test)\n",
    "\n",
    "print(\"accuracy: \", metrics.accuracy_score(y_test, y_predict))\n",
    "print('precision: ', metrics.precision_score(y_test, y_predict))\n",
    "print('recall: ', metrics.recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy isn't better, so the best option is to keep all the features.\n",
    "\n",
    "Just for funsies, checking the accuracy of naive bayes and k-neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes accuracy :  0.8873239436619719\n"
     ]
    }
   ],
   "source": [
    "# import the necessary module\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "#create an object of the type GaussianNB\n",
    "gnb = GaussianNB()\n",
    "#train the algorithm on training data and predict using the testing data\n",
    "pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "#print(pred.tolist())\n",
    "#print the accuracy score of the model\n",
    "print(\"Naive-Bayes accuracy : \",accuracy_score(y_test, pred, normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors accuracy score :  0.7887323943661971\n"
     ]
    }
   ],
   "source": [
    "#import necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#create object of the lassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "#Train the algorithm\n",
    "neigh.fit(X_train, y_train)\n",
    "# predict the response\n",
    "pred = neigh.predict(X_test)\n",
    "# evaluate accuracy\n",
    "print (\"KNeighbors accuracy score : \",accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither is better than the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
